#!/usr/bin/env bash
#
# Script: destroy-all-infrastructure.sh
# Purpose: Complete destruction of all AWS infrastructure created by this repository
# Author: Generated by Claude for static-site infrastructure cleanup
#
# DANGER: This script will PERMANENTLY DELETE all AWS resources created by this repository.
# This includes:
# - All S3 buckets and their contents
# - All KMS keys (scheduled for deletion)
# - All IAM roles, policies, and OIDC providers
# - All CloudFront distributions
# - All DynamoDB tables (Terraform state locks)
# - All CloudTrail trails and logs
# - All SNS topics and subscriptions
# - All CloudWatch alarms and log groups
# - All WAF Web ACLs
# - All Route53 hosted zones (if created)
# - All ACM certificates
# - Any orphaned EC2 resources (Elastic IPs, etc.)
#
# Required Environment Variables:
#   - AWS_DEFAULT_REGION: AWS region (default: us-east-1)
# Optional Environment Variables:
#   - FORCE_DESTROY: Set to 'true' to skip confirmation prompts
#   - DRY_RUN: Set to 'true' to see what would be destroyed without doing it
#   - ACCOUNT_FILTER: Comma-separated list of account IDs to limit destruction to
#
# Usage:
#   # Interactive mode with confirmations
#   ./destroy-all-infrastructure.sh
#
#   # Force mode (no confirmations)
#   FORCE_DESTROY=true ./destroy-all-infrastructure.sh
#
#   # Dry run mode (show what would be destroyed)
#   DRY_RUN=true ./destroy-all-infrastructure.sh
#
#   # Limit to specific accounts
#   ACCOUNT_FILTER="223938610551,822529998967" ./destroy-all-infrastructure.sh
#
# Exit Codes:
#   0 - Success (all resources destroyed)
#   1 - General failure
#   2 - User cancelled operation
#   3 - AWS CLI not configured
#   4 - Missing required permissions

set -euo pipefail

# Constants and Configuration
readonly SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
readonly SCRIPT_NAME="$(basename "${BASH_SOURCE[0]}")"
readonly LOG_FILE="/tmp/destroy-infrastructure-$(date +%Y%m%d-%H%M%S).log"

# Default values
: "${AWS_DEFAULT_REGION:=us-east-1}"
: "${FORCE_DESTROY:=false}"
: "${DRY_RUN:=false}"
: "${ACCOUNT_FILTER:=}"

# Colors for output (if terminal supports it)
if [[ -t 1 ]]; then
    readonly RED='\033[0;31m'
    readonly GREEN='\033[0;32m'
    readonly YELLOW='\033[1;33m'
    readonly BLUE='\033[0;34m'
    readonly BOLD='\033[1m'
    readonly NC='\033[0m' # No Color
else
    readonly RED=''
    readonly GREEN=''
    readonly YELLOW=''
    readonly BLUE=''
    readonly BOLD=''
    readonly NC=''
fi

# Project-specific resource patterns
readonly PROJECT_PATTERNS=(
    "static-site"
    "StaticSite"
    "terraform-state"
    "GitHubActions"
    "cloudtrail-logs"
)

# Logging functions
log_info() {
    echo -e "${BLUE}[INFO]${NC} $1" | tee -a "$LOG_FILE"
}

log_warn() {
    echo -e "${YELLOW}[WARN]${NC} $1" | tee -a "$LOG_FILE"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $1" | tee -a "$LOG_FILE"
}

log_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1" | tee -a "$LOG_FILE"
}

log_action() {
    if [[ "$DRY_RUN" == "true" ]]; then
        echo -e "${YELLOW}[DRY RUN]${NC} Would $1" | tee -a "$LOG_FILE"
    else
        echo -e "${BOLD}[ACTION]${NC} $1" | tee -a "$LOG_FILE"
    fi
}

# Confirmation function
confirm_destruction() {
    local resource_type="$1"
    local resource_name="$2"

    if [[ "$FORCE_DESTROY" == "true" ]] || [[ "$DRY_RUN" == "true" ]]; then
        return 0
    fi

    echo -e "${RED}${BOLD}DANGER:${NC} About to destroy ${YELLOW}$resource_type${NC}: ${BOLD}$resource_name${NC}"
    read -p "Are you sure? (type 'DELETE' to confirm): " confirmation

    if [[ "$confirmation" != "DELETE" ]]; then
        log_warn "Skipping $resource_type: $resource_name"
        return 1
    fi
    return 0
}

# Check if resource matches project patterns
matches_project() {
    local resource_name="$1"
    local pattern

    for pattern in "${PROJECT_PATTERNS[@]}"; do
        if [[ "$resource_name" == *"$pattern"* ]]; then
            return 0
        fi
    done
    return 1
}

# Check account filter
check_account_filter() {
    local account_id="$1"

    if [[ -z "$ACCOUNT_FILTER" ]]; then
        return 0  # No filter, allow all
    fi

    IFS=',' read -ra ACCOUNTS <<< "$ACCOUNT_FILTER"
    for allowed_account in "${ACCOUNTS[@]}"; do
        if [[ "$account_id" == "$allowed_account" ]]; then
            return 0
        fi
    done
    return 1
}

# AWS CLI wrapper with error handling
aws_cmd() {
    local cmd=("$@")

    if [[ "$DRY_RUN" == "true" ]]; then
        log_action "Run: aws ${cmd[*]}"
        return 0
    fi

    if ! aws "${cmd[@]}" 2>>"$LOG_FILE"; then
        log_error "Failed to execute: aws ${cmd[*]}"
        return 1
    fi
    return 0
}

# Destroy S3 buckets and contents
destroy_s3_buckets() {
    log_info "🪣 Scanning for S3 buckets..."

    local buckets
    buckets=$(aws s3api list-buckets --query 'Buckets[].Name' --output text 2>/dev/null || true)

    if [[ -z "$buckets" ]]; then
        log_info "No S3 buckets found"
        return 0
    fi

    for bucket in $buckets; do
        if matches_project "$bucket"; then
            if confirm_destruction "S3 Bucket" "$bucket"; then
                log_action "Empty and delete S3 bucket: $bucket"

                if [[ "$DRY_RUN" != "true" ]]; then
                    # Empty bucket first (including all versions and delete markers)
                    aws s3api list-object-versions --bucket "$bucket" \
                        --query 'Versions[].{Key:Key,VersionId:VersionId}' \
                        --output text 2>/dev/null | \
                        while read -r key version_id; do
                            [[ -n "$key" ]] && aws s3api delete-object --bucket "$bucket" --key "$key" --version-id "$version_id" 2>/dev/null || true
                        done

                    # Delete delete markers
                    aws s3api list-object-versions --bucket "$bucket" \
                        --query 'DeleteMarkers[].{Key:Key,VersionId:VersionId}' \
                        --output text 2>/dev/null | \
                        while read -r key version_id; do
                            [[ -n "$key" ]] && aws s3api delete-object --bucket "$bucket" --key "$key" --version-id "$version_id" 2>/dev/null || true
                        done

                    # Force empty using CLI (as backup)
                    aws s3 rm "s3://$bucket" --recursive 2>/dev/null || true

                    # Delete bucket
                    if aws s3api delete-bucket --bucket "$bucket" 2>/dev/null; then
                        log_success "Deleted S3 bucket: $bucket"
                    else
                        log_error "Failed to delete S3 bucket: $bucket"
                    fi
                fi
            fi
        fi
    done
}

# Destroy CloudFront distributions
destroy_cloudfront_distributions() {
    log_info "🌐 Scanning for CloudFront distributions..."

    local distributions
    distributions=$(aws cloudfront list-distributions --query 'DistributionList.Items[].{Id:Id,DomainName:DomainName,Comment:Comment,Status:Status}' --output json 2>/dev/null || echo "[]")

    if [[ "$distributions" == "[]" ]]; then
        log_info "No CloudFront distributions found"
        return 0
    fi

    echo "$distributions" | jq -c '.[]' | while read -r distribution; do
        local dist_id
        local comment
        local status

        dist_id=$(echo "$distribution" | jq -r '.Id')
        comment=$(echo "$distribution" | jq -r '.Comment // ""')
        status=$(echo "$distribution" | jq -r '.Status')

        if matches_project "$comment" || matches_project "$dist_id"; then
            if confirm_destruction "CloudFront Distribution" "$dist_id ($comment)"; then
                log_action "Disable and delete CloudFront distribution: $dist_id"

                if [[ "$DRY_RUN" != "true" ]]; then
                    # Get current config
                    local config etag
                    config=$(aws cloudfront get-distribution-config --id "$dist_id" --query 'DistributionConfig' --output json)
                    etag=$(aws cloudfront get-distribution-config --id "$dist_id" --query 'ETag' --output text)

                    # Disable distribution if enabled
                    if [[ "$(echo "$config" | jq -r '.Enabled')" == "true" ]]; then
                        config=$(echo "$config" | jq '.Enabled = false')

                        if aws cloudfront update-distribution --id "$dist_id" --distribution-config "$config" --if-match "$etag" >/dev/null; then
                            log_info "Distribution $dist_id disabled, waiting for deployment..."

                            # Wait for distribution to be deployed
                            local attempts=0
                            while [[ $attempts -lt 30 ]]; do
                                status=$(aws cloudfront get-distribution --id "$dist_id" --query 'Distribution.Status' --output text)
                                if [[ "$status" == "Deployed" ]]; then
                                    break
                                fi
                                log_info "Waiting for distribution $dist_id to be deployed (status: $status)..."
                                sleep 30
                                ((attempts++))
                            done
                        fi
                    fi

                    # Delete distribution (only works when disabled and deployed)
                    etag=$(aws cloudfront get-distribution --id "$dist_id" --query 'ETag' --output text)
                    if aws cloudfront delete-distribution --id "$dist_id" --if-match "$etag" 2>/dev/null; then
                        log_success "Deleted CloudFront distribution: $dist_id"
                    else
                        log_warn "Could not delete CloudFront distribution $dist_id (may need manual intervention)"
                    fi
                fi
            fi
        fi
    done
}

# Destroy DynamoDB tables
destroy_dynamodb_tables() {
    log_info "🗃️  Scanning for DynamoDB tables..."

    local tables
    tables=$(aws dynamodb list-tables --query 'TableNames[]' --output text 2>/dev/null || true)

    if [[ -z "$tables" ]]; then
        log_info "No DynamoDB tables found"
        return 0
    fi

    for table in $tables; do
        if matches_project "$table"; then
            if confirm_destruction "DynamoDB Table" "$table"; then
                log_action "Delete DynamoDB table: $table"

                if [[ "$DRY_RUN" != "true" ]]; then
                    if aws dynamodb delete-table --table-name "$table" >/dev/null 2>&1; then
                        log_success "Deleted DynamoDB table: $table"
                    else
                        log_error "Failed to delete DynamoDB table: $table"
                    fi
                fi
            fi
        fi
    done
}

# Destroy KMS keys
destroy_kms_keys() {
    log_info "🔐 Scanning for KMS keys..."

    # Get all aliases first
    local aliases
    aliases=$(aws kms list-aliases --query 'Aliases[].{AliasName:AliasName,TargetKeyId:TargetKeyId}' --output json 2>/dev/null || echo "[]")

    echo "$aliases" | jq -c '.[]' | while read -r alias_info; do
        local alias_name target_key_id
        alias_name=$(echo "$alias_info" | jq -r '.AliasName')
        target_key_id=$(echo "$alias_info" | jq -r '.TargetKeyId // ""')

        if matches_project "$alias_name" && [[ -n "$target_key_id" ]]; then
            if confirm_destruction "KMS Key" "$alias_name ($target_key_id)"; then
                log_action "Schedule KMS key deletion: $alias_name"

                if [[ "$DRY_RUN" != "true" ]]; then
                    # Delete alias first
                    if aws kms delete-alias --alias-name "$alias_name" 2>/dev/null; then
                        log_success "Deleted KMS alias: $alias_name"
                    fi

                    # Schedule key deletion (7 day minimum)
                    if aws kms schedule-key-deletion --key-id "$target_key_id" --pending-window-in-days 7 >/dev/null 2>&1; then
                        log_success "Scheduled KMS key deletion: $target_key_id (7 days)"
                    else
                        log_error "Failed to schedule KMS key deletion: $target_key_id"
                    fi
                fi
            fi
        fi
    done
}

# Destroy IAM resources
destroy_iam_resources() {
    log_info "👤 Scanning for IAM resources..."

    # Get current account ID for validation
    local current_account
    current_account=$(aws sts get-caller-identity --query 'Account' --output text)

    if ! check_account_filter "$current_account"; then
        log_warn "Skipping IAM resources - account $current_account not in filter"
        return 0
    fi

    # Destroy IAM roles
    local roles
    roles=$(aws iam list-roles --query 'Roles[].{RoleName:RoleName,Arn:Arn}' --output json 2>/dev/null || echo "[]")

    echo "$roles" | jq -c '.[]' | while read -r role_info; do
        local role_name role_arn
        role_name=$(echo "$role_info" | jq -r '.RoleName')
        role_arn=$(echo "$role_info" | jq -r '.Arn')

        if matches_project "$role_name"; then
            if confirm_destruction "IAM Role" "$role_name"; then
                log_action "Delete IAM role: $role_name"

                if [[ "$DRY_RUN" != "true" ]]; then
                    # Detach managed policies
                    aws iam list-attached-role-policies --role-name "$role_name" --query 'AttachedPolicies[].PolicyArn' --output text 2>/dev/null | \
                        while read -r policy_arn; do
                            [[ -n "$policy_arn" ]] && aws iam detach-role-policy --role-name "$role_name" --policy-arn "$policy_arn" 2>/dev/null || true
                        done

                    # Delete inline policies
                    aws iam list-role-policies --role-name "$role_name" --query 'PolicyNames[]' --output text 2>/dev/null | \
                        while read -r policy_name; do
                            [[ -n "$policy_name" ]] && aws iam delete-role-policy --role-name "$role_name" --policy-name "$policy_name" 2>/dev/null || true
                        done

                    # Delete role
                    if aws iam delete-role --role-name "$role_name" 2>/dev/null; then
                        log_success "Deleted IAM role: $role_name"
                    else
                        log_error "Failed to delete IAM role: $role_name"
                    fi
                fi
            fi
        fi
    done

    # Destroy custom IAM policies
    local policies
    policies=$(aws iam list-policies --scope Local --query 'Policies[].{PolicyName:PolicyName,Arn:Arn}' --output json 2>/dev/null || echo "[]")

    echo "$policies" | jq -c '.[]' | while read -r policy_info; do
        local policy_name policy_arn
        policy_name=$(echo "$policy_info" | jq -r '.PolicyName')
        policy_arn=$(echo "$policy_info" | jq -r '.Arn')

        if matches_project "$policy_name"; then
            if confirm_destruction "IAM Policy" "$policy_name"; then
                log_action "Delete IAM policy: $policy_name"

                if [[ "$DRY_RUN" != "true" ]]; then
                    # Delete all policy versions except default
                    aws iam list-policy-versions --policy-arn "$policy_arn" --query 'Versions[?!IsDefaultVersion].VersionId' --output text 2>/dev/null | \
                        while read -r version_id; do
                            [[ -n "$version_id" ]] && aws iam delete-policy-version --policy-arn "$policy_arn" --version-id "$version_id" 2>/dev/null || true
                        done

                    # Delete policy
                    if aws iam delete-policy --policy-arn "$policy_arn" 2>/dev/null; then
                        log_success "Deleted IAM policy: $policy_name"
                    else
                        log_error "Failed to delete IAM policy: $policy_name"
                    fi
                fi
            fi
        fi
    done

    # Destroy OIDC identity providers
    local oidc_providers
    oidc_providers=$(aws iam list-open-id-connect-providers --query 'OpenIDConnectProviderList[].Arn' --output text 2>/dev/null || true)

    for provider_arn in $oidc_providers; do
        if [[ "$provider_arn" == *"token.actions.githubusercontent.com"* ]]; then
            if confirm_destruction "OIDC Identity Provider" "$provider_arn"; then
                log_action "Delete OIDC identity provider: $provider_arn"

                if [[ "$DRY_RUN" != "true" ]]; then
                    if aws iam delete-open-id-connect-provider --open-id-connect-provider-arn "$provider_arn" 2>/dev/null; then
                        log_success "Deleted OIDC identity provider: $provider_arn"
                    else
                        log_error "Failed to delete OIDC identity provider: $provider_arn"
                    fi
                fi
            fi
        fi
    done
}

# Destroy CloudWatch resources
destroy_cloudwatch_resources() {
    log_info "📊 Scanning for CloudWatch resources..."

    # Destroy log groups
    local log_groups
    log_groups=$(aws logs describe-log-groups --query 'logGroups[].logGroupName' --output text 2>/dev/null || true)

    for log_group in $log_groups; do
        if matches_project "$log_group" || [[ "$log_group" == *"/aws/cloudtrail"* ]]; then
            if confirm_destruction "CloudWatch Log Group" "$log_group"; then
                log_action "Delete CloudWatch log group: $log_group"

                if [[ "$DRY_RUN" != "true" ]]; then
                    if aws logs delete-log-group --log-group-name "$log_group" 2>/dev/null; then
                        log_success "Deleted CloudWatch log group: $log_group"
                    else
                        log_error "Failed to delete CloudWatch log group: $log_group"
                    fi
                fi
            fi
        fi
    done

    # Destroy alarms
    local alarms
    alarms=$(aws cloudwatch describe-alarms --query 'MetricAlarms[].AlarmName' --output text 2>/dev/null || true)

    for alarm in $alarms; do
        if matches_project "$alarm"; then
            if confirm_destruction "CloudWatch Alarm" "$alarm"; then
                log_action "Delete CloudWatch alarm: $alarm"

                if [[ "$DRY_RUN" != "true" ]]; then
                    if aws cloudwatch delete-alarms --alarm-names "$alarm" 2>/dev/null; then
                        log_success "Deleted CloudWatch alarm: $alarm"
                    else
                        log_error "Failed to delete CloudWatch alarm: $alarm"
                    fi
                fi
            fi
        fi
    done
}

# Destroy SNS resources
destroy_sns_resources() {
    log_info "📢 Scanning for SNS resources..."

    local topics
    topics=$(aws sns list-topics --query 'Topics[].TopicArn' --output text 2>/dev/null || true)

    for topic_arn in $topics; do
        local topic_name
        topic_name=$(basename "$topic_arn")

        if matches_project "$topic_name"; then
            if confirm_destruction "SNS Topic" "$topic_name"; then
                log_action "Delete SNS topic: $topic_arn"

                if [[ "$DRY_RUN" != "true" ]]; then
                    if aws sns delete-topic --topic-arn "$topic_arn" 2>/dev/null; then
                        log_success "Deleted SNS topic: $topic_name"
                    else
                        log_error "Failed to delete SNS topic: $topic_name"
                    fi
                fi
            fi
        fi
    done
}

# Destroy CloudTrail resources
destroy_cloudtrail_resources() {
    log_info "📋 Scanning for CloudTrail resources..."

    local trails
    trails=$(aws cloudtrail describe-trails --query 'trailList[].{Name:Name,S3BucketName:S3BucketName}' --output json 2>/dev/null || echo "[]")

    echo "$trails" | jq -c '.[]' | while read -r trail_info; do
        local trail_name s3_bucket
        trail_name=$(echo "$trail_info" | jq -r '.Name')
        s3_bucket=$(echo "$trail_info" | jq -r '.S3BucketName // ""')

        if matches_project "$trail_name" || matches_project "$s3_bucket"; then
            if confirm_destruction "CloudTrail Trail" "$trail_name"; then
                log_action "Delete CloudTrail trail: $trail_name"

                if [[ "$DRY_RUN" != "true" ]]; then
                    # Stop logging first
                    aws cloudtrail stop-logging --name "$trail_name" 2>/dev/null || true

                    # Delete trail
                    if aws cloudtrail delete-trail --name "$trail_name" 2>/dev/null; then
                        log_success "Deleted CloudTrail trail: $trail_name"
                    else
                        log_error "Failed to delete CloudTrail trail: $trail_name"
                    fi
                fi
            fi
        fi
    done
}

# Destroy WAF resources
destroy_waf_resources() {
    log_info "🛡️  Scanning for WAF resources..."

    # Check CloudFront scope
    local web_acls
    web_acls=$(aws wafv2 list-web-acls --scope CLOUDFRONT --query 'WebACLs[].{Name:Name,Id:Id}' --output json 2>/dev/null || echo "[]")

    echo "$web_acls" | jq -c '.[]' | while read -r web_acl; do
        local name id
        name=$(echo "$web_acl" | jq -r '.Name')
        id=$(echo "$web_acl" | jq -r '.Id')

        if matches_project "$name"; then
            if confirm_destruction "WAF Web ACL" "$name"; then
                log_action "Delete WAF Web ACL: $name"

                if [[ "$DRY_RUN" != "true" ]]; then
                    # Get lock token
                    local lock_token
                    lock_token=$(aws wafv2 get-web-acl --scope CLOUDFRONT --id "$id" --name "$name" --query 'LockToken' --output text 2>/dev/null || true)

                    if [[ -n "$lock_token" ]] && aws wafv2 delete-web-acl --scope CLOUDFRONT --id "$id" --name "$name" --lock-token "$lock_token" 2>/dev/null; then
                        log_success "Deleted WAF Web ACL: $name"
                    else
                        log_error "Failed to delete WAF Web ACL: $name"
                    fi
                fi
            fi
        fi
    done
}

# Cleanup orphaned resources that cost money
cleanup_orphaned_resources() {
    log_info "🧹 Scanning for orphaned resources that cost money..."

    # Unassociated Elastic IPs
    log_info "Checking for unassociated Elastic IPs..."
    local eips
    eips=$(timeout 30 aws ec2 describe-addresses --query 'Addresses[?AssociationId==null].{PublicIp:PublicIp,AllocationId:AllocationId}' --output json 2>/dev/null || echo "[]")

    if [[ "$eips" != "[]" ]]; then
        echo "$eips" | jq -c '.[]' | while read -r eip; do
            local public_ip allocation_id
            public_ip=$(echo "$eip" | jq -r '.PublicIp')
            allocation_id=$(echo "$eip" | jq -r '.AllocationId')

            if confirm_destruction "Orphaned Elastic IP" "$public_ip"; then
                log_action "Release Elastic IP: $public_ip"

                if [[ "$DRY_RUN" != "true" ]]; then
                    if aws ec2 release-address --allocation-id "$allocation_id" 2>/dev/null; then
                        log_success "Released Elastic IP: $public_ip"
                    else
                        log_error "Failed to release Elastic IP: $public_ip"
                    fi
                fi
            fi
        done
    fi
}

# Generate cost estimate
generate_cost_estimate() {
    log_info "💰 Generating monthly cost estimate for destroyed resources..."

    # This is a rough estimate based on typical AWS pricing
    local total_monthly_savings=0

    # Estimate savings (very rough)
    local s3_buckets_count
    s3_buckets_count=$(aws s3api list-buckets --query 'Buckets[].Name' --output text 2>/dev/null | wc -w || echo 0)

    local cloudfront_count
    cloudfront_count=$(aws cloudfront list-distributions --query 'DistributionList.Items[].Id' --output text 2>/dev/null | wc -w || echo 0)

    # Rough monthly cost estimates (in USD)
    local s3_cost=$((s3_buckets_count * 5))      # ~$5/month per bucket (very rough)
    local cloudfront_cost=$((cloudfront_count * 10))  # ~$10/month per distribution
    local dynamodb_cost=5                        # ~$5/month for state locking
    local kms_cost=10                            # ~$1/month per key + usage

    total_monthly_savings=$((s3_cost + cloudfront_cost + dynamodb_cost + kms_cost))

    log_success "Estimated monthly cost savings: \$${total_monthly_savings} USD"
    log_info "Note: This is a rough estimate. Actual costs depend on usage, data transfer, and storage."
}

# Main execution function
main() {
    local start_time
    start_time=$(date +%s)

    echo -e "${BOLD}${RED}"
    echo "╔══════════════════════════════════════════════════════════════╗"
    echo "║                    🚨 DANGER ZONE 🚨                        ║"
    echo "║                                                              ║"
    echo "║  This script will PERMANENTLY DELETE all AWS resources      ║"
    echo "║  created by the static-site infrastructure repository.      ║"
    echo "║                                                              ║"
    echo "║  Resources that will be destroyed:                          ║"
    echo "║  • S3 buckets and all contents                              ║"
    echo "║  • KMS keys (scheduled for deletion)                       ║"
    echo "║  • IAM roles, policies, and OIDC providers                 ║"
    echo "║  • CloudFront distributions                                 ║"
    echo "║  • DynamoDB tables                                          ║"
    echo "║  • CloudTrail trails and logs                              ║"
    echo "║  • All other project-related AWS resources                 ║"
    echo "║                                                              ║"
    echo "║  💸 This action may result in significant cost savings      ║"
    echo "║  💀 This action CANNOT be undone                           ║"
    echo "╚══════════════════════════════════════════════════════════════╝"
    echo -e "${NC}"

    log_info "Starting infrastructure destruction script"
    log_info "Log file: $LOG_FILE"
    log_info "Dry run mode: $DRY_RUN"
    log_info "Force mode: $FORCE_DESTROY"
    log_info "AWS Region: $AWS_DEFAULT_REGION"

    if [[ -n "$ACCOUNT_FILTER" ]]; then
        log_info "Account filter: $ACCOUNT_FILTER"
    fi

    # Verify AWS CLI is configured
    if ! aws sts get-caller-identity >/dev/null 2>&1; then
        log_error "AWS CLI is not configured or lacks permissions"
        log_error "Please run 'aws configure' or set up AWS credentials"
        exit 3
    fi

    local current_account current_region
    current_account=$(aws sts get-caller-identity --query 'Account' --output text)
    current_region=$(aws configure get region || echo "$AWS_DEFAULT_REGION")

    log_info "Current AWS Account: $current_account"
    log_info "Current AWS Region: $current_region"

    # Final confirmation
    if [[ "$FORCE_DESTROY" != "true" ]] && [[ "$DRY_RUN" != "true" ]]; then
        echo
        echo -e "${RED}${BOLD}FINAL WARNING:${NC}"
        echo "You are about to destroy ALL infrastructure in AWS account: $current_account"
        echo "This includes PERMANENT deletion of data and resources."
        echo
        read -p "Type 'DESTROY EVERYTHING' to confirm: " final_confirmation

        if [[ "$final_confirmation" != "DESTROY EVERYTHING" ]]; then
            log_warn "Operation cancelled by user"
            exit 2
        fi
    fi

    log_info "Beginning destruction sequence..."

    # Execute destruction in order (dependent resources first)
    destroy_cloudfront_distributions
    destroy_waf_resources
    destroy_s3_buckets
    destroy_cloudtrail_resources
    destroy_cloudwatch_resources
    destroy_sns_resources
    destroy_dynamodb_tables
    destroy_iam_resources
    destroy_kms_keys
    cleanup_orphaned_resources

    # Generate cost savings estimate
    generate_cost_estimate

    local end_time duration
    end_time=$(date +%s)
    duration=$((end_time - start_time))

    log_success "Infrastructure destruction completed in ${duration} seconds"
    log_success "Log file saved: $LOG_FILE"

    if [[ "$DRY_RUN" == "true" ]]; then
        echo
        log_info "This was a DRY RUN. No resources were actually destroyed."
        log_info "Review the log file to see what would be destroyed."
        log_info "Run without DRY_RUN=true to perform actual destruction."
    else
        echo
        log_success "🎉 All infrastructure has been destroyed!"
        log_success "💰 You should see cost savings on your next AWS bill"
        echo
        log_warn "Note: Some resources like KMS keys have mandatory waiting periods"
        log_warn "Check the AWS console to verify all resources are gone"
    fi
}

# Script entry point
if [[ "${BASH_SOURCE[0]}" == "${0}" ]]; then
    main "$@"
fi