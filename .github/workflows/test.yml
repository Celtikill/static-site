name: TEST - Quality Gates and Validation

on:
  workflow_run:
    workflows: ["BUILD - Code Validation and Artifact Creation"]
    types: [completed]
    branches: [main, 'feature/*', 'bugfix/*', 'hotfix/*']
  workflow_dispatch:
    inputs:
      build_id:
        description: 'Build ID to test (optional)'
        required: false
        type: string
      environment:
        description: 'Target environment'
        required: false
        type: choice
        options: [dev, staging, prod]
        default: dev
      skip_build_check:
        description: 'Skip BUILD workflow dependency check'
        required: false
        type: boolean
        default: true
      force_all_jobs:
        description: 'Force all jobs to run regardless of change detection'
        required: false
        type: boolean
        default: false

permissions:
  id-token: write
  contents: read
  pull-requests: write
  security-events: write
  actions: read

env:
  AWS_DEFAULT_REGION: ${{ vars.AWS_DEFAULT_REGION }}
  OPENTOFU_VERSION: ${{ vars.OPENTOFU_VERSION }}
  TF_IN_AUTOMATION: true

concurrency:
  group: test-${{ github.ref }}
  cancel-in-progress: true

jobs:
  info:
    name: "üìã Test Information"
    runs-on: ubuntu-latest
    timeout-minutes: 5
    # Always require BUILD success for automatic triggers
    # Manual dispatch allowed only for non-dev environments or with explicit override
    if: |
      github.event.workflow_run.conclusion == 'success' ||
      (github.event_name == 'workflow_dispatch' && 
       (github.event.inputs.environment == 'staging' || 
        github.event.inputs.environment == 'prod' ||
        github.event.inputs.skip_build_check == 'true'))
    outputs:
      test_id: ${{ steps.info.outputs.test_id }}
      build_id: ${{ steps.info.outputs.build_id }}
      environment: ${{ steps.info.outputs.environment }}
      has_terraform_changes: ${{ steps.detect.outputs.terraform }}
      has_website_changes: ${{ steps.detect.outputs.website }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          # For workflow_run triggers, explicitly check out the branch that triggered the original workflow
          ref: ${{ github.event_name == 'workflow_run' && github.event.workflow_run.head_branch || github.ref }}

      # Branch detection simplified - workflow runs on the triggering branch by default
      # No need for API calls to detect branch - github.ref_name gives us the correct branch

      - name: Test Info
        id: info
        run: |
          TEST_ID="test-${{ github.run_id }}-${{ github.run_attempt }}"

          # Determine build ID
          if [ -n "${{ github.event.inputs.build_id }}" ]; then
            BUILD_ID="${{ github.event.inputs.build_id }}"
          else
            BUILD_ID="build-${{ github.event.workflow_run.id || github.run_id }}"
          fi

          # Use the triggering branch directly (workflow runs on the correct branch by default)
          SOURCE_BRANCH="${{ github.ref_name }}"

          # Determine target environment based on source branch
          if [ -n "${{ github.event.inputs.environment }}" ]; then
            ENV="${{ github.event.inputs.environment }}"
            ENV_SOURCE="Manual Input"
          elif [[ "$SOURCE_BRANCH" =~ ^(feature|bugfix|hotfix)/ ]]; then
            ENV="dev"
            ENV_SOURCE="Feature Branch Auto-Test"
          elif [ "$SOURCE_BRANCH" = "main" ]; then
            ENV="staging"
            ENV_SOURCE="Main Branch Auto-Test"
          else
            ENV="dev"
            ENV_SOURCE="Default"
          fi

          # Validate dev deployment policy
          if [ "${{ github.event_name }}" = "workflow_dispatch" ] && [ "$ENV" = "dev" ] && [ "${{ github.event.inputs.skip_build_check }}" != "true" ]; then
            echo "‚ùå **POLICY VIOLATION**: Manual dispatch to dev environment requires BUILD success" >> $GITHUB_STEP_SUMMARY
            echo "   Use skip_build_check=true to override this policy (not recommended)" >> $GITHUB_STEP_SUMMARY
            exit 1
          fi

          echo "test_id=$TEST_ID" >> $GITHUB_OUTPUT
          echo "build_id=$BUILD_ID" >> $GITHUB_OUTPUT
          echo "environment=$ENV" >> $GITHUB_OUTPUT

          echo "# üß™ TEST Phase" >> $GITHUB_STEP_SUMMARY
          echo "- **Test ID**: $TEST_ID" >> $GITHUB_STEP_SUMMARY
          echo "- **Build ID**: $BUILD_ID" >> $GITHUB_STEP_SUMMARY
          echo "- **Environment**: $ENV ($ENV_SOURCE)" >> $GITHUB_STEP_SUMMARY
          echo "- **Branch**: $SOURCE_BRANCH" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## üîç Job Execution Decisions" >> $GITHUB_STEP_SUMMARY
          echo "- **Force All Jobs**: ${{ github.event.inputs.force_all_jobs || 'false' }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Skip Build Check**: ${{ github.event.inputs.skip_build_check || 'false' }}" >> $GITHUB_STEP_SUMMARY

      - name: Detect Changes
        id: detect
        uses: dorny/paths-filter@v3
        with:
          filters: |
            terraform:
              - 'terraform/**'
            website:
              - 'src/**'

      - name: Debug Change Detection
        run: |
          echo "- **Terraform Changes**: ${{ steps.detect.outputs.terraform }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Website Changes**: ${{ steps.detect.outputs.website }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Job Execution Logic:" >> $GITHUB_STEP_SUMMARY
          echo "- **Infrastructure Tests**: Will run if terraform changes OR skip_build_check OR force_all_jobs" >> $GITHUB_STEP_SUMMARY
          echo "- **Policy Validation**: Will run if terraform changes OR skip_build_check OR force_all_jobs" >> $GITHUB_STEP_SUMMARY
          echo "- **Website Tests**: Will run if website changes OR skip_build_check OR force_all_jobs" >> $GITHUB_STEP_SUMMARY
          echo "- **Pre-Deployment Usability**: Will run if environment != dev OR force_all_jobs" >> $GITHUB_STEP_SUMMARY

  infrastructure-tests:
    name: "üèóÔ∏è Infrastructure Unit Tests"
    runs-on: ubuntu-latest
    timeout-minutes: 15
    needs: info
    if: needs.info.outputs.has_terraform_changes == 'true' || github.event.inputs.skip_build_check == 'true' || github.event.inputs.force_all_jobs == 'true'
    env:
      AWS_ASSUME_ROLE_DEV: ${{ secrets.AWS_ASSUME_ROLE_DEV }}
      AWS_ASSUME_ROLE_STAGING: ${{ secrets.AWS_ASSUME_ROLE_STAGING }}
      AWS_ASSUME_ROLE: ${{ secrets.AWS_ASSUME_ROLE }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Download Build Artifacts
        uses: actions/download-artifact@v4
        continue-on-error: true
        with:
          name: build-artifacts-${{ needs.info.outputs.build_id }}
          path: ./artifacts

      - name: Setup Infrastructure Tools
        run: |
          echo "## üîß Setting up infrastructure test tools" >> $GITHUB_STEP_SUMMARY

          # Install OpenTofu for infrastructure tests
          curl -L -o /tmp/tofu.zip https://github.com/opentofu/opentofu/releases/download/v${{ env.OPENTOFU_VERSION }}/tofu_${{ env.OPENTOFU_VERSION }}_linux_amd64.zip
          unzip -q /tmp/tofu.zip -d /tmp
          sudo mv /tmp/tofu /usr/local/bin/

          # Install jq for JSON processing
          sudo apt-get update && sudo apt-get install -y jq

          echo "‚úÖ Infrastructure tools ready" >> $GITHUB_STEP_SUMMARY

      - name: Run Comprehensive Unit Tests
        run: |
          echo "## üèóÔ∏è Running Comprehensive Unit Tests" >> $GITHUB_STEP_SUMMARY

          # Make test scripts executable
          chmod +x test/unit/test-static-analysis.sh
          chmod +x test/unit/run-tests.sh

          # Run static analysis tests (no AWS dependencies)
          if bash test/unit/test-static-analysis.sh; then
            echo "‚úÖ Static analysis tests passed" >> $GITHUB_STEP_SUMMARY
          else
            echo "‚ùå Static analysis tests failed" >> $GITHUB_STEP_SUMMARY
            exit 1
          fi

          # Run unit tests individually to avoid orchestrator hanging issues
          TEST_FAILED=0
          TOTAL_TESTS=0
          TOTAL_INDIVIDUAL_TESTS=0
          PASSED_INDIVIDUAL_TESTS=0
          FAILED_TEST_DETAILS=()
          
          echo "**Running Individual Test Suites:**" >> $GITHUB_STEP_SUMMARY
          
          for test_file in test/unit/test-*.sh; do
            if [[ -f "$test_file" && ! "$test_file" == *".disabled" ]]; then
              test_name=$(basename "$test_file" .sh)
              echo "Running $test_name..."
              
              if bash "$test_file"; then
                echo "- ‚úÖ $test_name: PASSED" >> $GITHUB_STEP_SUMMARY
                
                # Update individual test counts for passing tests  
                result_file="test/unit/test-results/${test_name/test-/}-tests-tests-report.json"
                if [ -f "$result_file" ]; then
                  suite_total=$(jq -r '.summary.total_tests // 0' "$result_file" 2>/dev/null || echo "0")
                  TOTAL_INDIVIDUAL_TESTS=$((TOTAL_INDIVIDUAL_TESTS + suite_total))
                  PASSED_INDIVIDUAL_TESTS=$((PASSED_INDIVIDUAL_TESTS + suite_total))
                fi
              else
                echo "- ‚ùå $test_name: FAILED" >> $GITHUB_STEP_SUMMARY
                TEST_FAILED=1
                
                # Extract failure details from test result file if it exists
                result_file="test/unit/test-results/${test_name/test-/}-tests-tests-report.json"
                if [ -f "$result_file" ]; then
                  # Get basic stats
                  suite_total=$(jq -r '.summary.total_tests // 0' "$result_file" 2>/dev/null || echo "0")
                  suite_failed=$(jq -r '.summary.failed_tests // 0' "$result_file" 2>/dev/null || echo "0")
                  
                  # Add to overall counts
                  TOTAL_INDIVIDUAL_TESTS=$((TOTAL_INDIVIDUAL_TESTS + suite_total))
                  PASSED_INDIVIDUAL_TESTS=$((PASSED_INDIVIDUAL_TESTS + suite_total - suite_failed))
                  
                  # Extract specific failure details from log file
                  log_file="test/unit/test-results/test-${test_name/test-/}-tests.log"
                  if [ -f "$log_file" ]; then
                    # Extract each failed test as a separate bullet point
                    while IFS= read -r failed_line; do
                      if [ -n "$failed_line" ]; then
                        test_detail=$(echo "$failed_line" | sed 's/.*‚ùå //' | sed 's/: /: /')
                        FAILED_TEST_DETAILS+=("$test_detail")
                      fi
                    done < <(grep "‚ùå" "$log_file" | head -5)
                  fi
                else
                  # Fallback if no result file
                  FAILED_TEST_DETAILS+=("$test_name: Test suite failed (details not available)")
                fi
              fi
              
              TOTAL_TESTS=$((TOTAL_TESTS + 1))
            fi
          done
          
          # Display comprehensive summary
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Test Suite Summary:**" >> $GITHUB_STEP_SUMMARY
          echo "- Test Suites: $(($TOTAL_TESTS - $TEST_FAILED)) passed, $TEST_FAILED failed, $TOTAL_TESTS total" >> $GITHUB_STEP_SUMMARY
          
          if [ $TOTAL_INDIVIDUAL_TESTS -gt 0 ]; then
            success_rate=$(( (PASSED_INDIVIDUAL_TESTS * 100) / TOTAL_INDIVIDUAL_TESTS ))
            echo "- Individual Tests: $PASSED_INDIVIDUAL_TESTS passed, $(($TOTAL_INDIVIDUAL_TESTS - $PASSED_INDIVIDUAL_TESTS)) failed, $TOTAL_INDIVIDUAL_TESTS total" >> $GITHUB_STEP_SUMMARY
            echo "- Success Rate: ${success_rate}%" >> $GITHUB_STEP_SUMMARY
          fi
          
          # Show specific failure details
          if [ $TEST_FAILED -gt 0 ] && [ ${#FAILED_TEST_DETAILS[@]} -gt 0 ]; then
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "**Failed Test Details:**" >> $GITHUB_STEP_SUMMARY
            for detail in "${FAILED_TEST_DETAILS[@]}"; do
              echo "- $detail" >> $GITHUB_STEP_SUMMARY
            done
          fi
          
          if [ $TEST_FAILED -eq 0 ]; then
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "‚úÖ All unit tests passed successfully" >> $GITHUB_STEP_SUMMARY
          else
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "‚ùå One or more unit tests failed - see details above" >> $GITHUB_STEP_SUMMARY
            exit 1
          fi


      - name: Upload Unit Test Results
        uses: actions/upload-artifact@v4
        with:
          name: unit-test-results-${{ needs.info.outputs.test_id }}
          path: test/unit/test-results/
          retention-days: 7

  policy-validation:
    name: "üìã Policy Validation"
    runs-on: ubuntu-latest
    timeout-minutes: 8
    needs: [info, infrastructure-tests]
    if: needs.info.outputs.has_terraform_changes == 'true' || github.event.inputs.skip_build_check == 'true' || github.event.inputs.force_all_jobs == 'true'
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Download Infrastructure Test Results
        uses: actions/download-artifact@v4
        continue-on-error: true
        with:
          name: unit-test-results-${{ needs.info.outputs.test_id }}
          path: ./test-results

      - name: Setup Policy Tools
        run: |
          echo "## üîß Policy Tools Setup" >> $GITHUB_STEP_SUMMARY

          # Install OpenTofu
          curl -L -o /tmp/tofu.zip https://github.com/opentofu/opentofu/releases/download/v${{ env.OPENTOFU_VERSION }}/tofu_${{ env.OPENTOFU_VERSION }}_linux_amd64.zip
          unzip -q /tmp/tofu.zip -d /tmp
          sudo mv /tmp/tofu /usr/local/bin/

          # Install policy tools
          curl -L -o /tmp/opa https://github.com/open-policy-agent/opa/releases/download/v0.59.0/opa_linux_amd64_static
          chmod +x /tmp/opa
          sudo mv /tmp/opa /usr/local/bin/

          echo "‚úÖ Policy tools ready" >> $GITHUB_STEP_SUMMARY

      - name: Policy Validation Tests
        run: |
          echo "## üìã Policy Validation" >> $GITHUB_STEP_SUMMARY

          # Determine environment for policy enforcement
          ENV="${{ needs.info.outputs.environment }}"
          echo "- **Environment**: $ENV" >> $GITHUB_STEP_SUMMARY

          # Create basic security policies
          mkdir -p policies
          cat > policies/security.rego << 'EOF'
          package terraform.security

          # Ensure S3 buckets have encryption
          deny[msg] {
            resource := input.planned_values.root_module.resources[_]
            resource.type == "aws_s3_bucket"
            not resource.values.server_side_encryption_configuration
            msg := sprintf("S3 bucket '%s' must have encryption enabled", [resource.name])
          }

          # Ensure CloudFront distributions use HTTPS
          deny[msg] {
            resource := input.planned_values.root_module.resources[_]
            resource.type == "aws_cloudfront_distribution"
            resource.values.viewer_protocol_policy != "redirect-to-https"
            msg := sprintf("CloudFront distribution '%s' must redirect HTTP to HTTPS", [resource.name])
          }
          EOF

          # Run policy validation
          if [ -f "terraform/test.tfplan" ]; then
            tofu -chdir=terraform show -json test.tfplan > plan.json
            POLICY_VIOLATIONS=$(opa eval -d policies/ -i plan.json "data.terraform.security.deny[x]" --format pretty | grep -c "true" || echo "0")

            if [ "$POLICY_VIOLATIONS" -gt 0 ]; then
              echo "‚ö†Ô∏è **$POLICY_VIOLATIONS policy violation(s) found**" >> $GITHUB_STEP_SUMMARY

              # Environment-specific enforcement
              if [ "$ENV" = "prod" ]; then
                echo "‚ùå **PRODUCTION DEPLOYMENT BLOCKED** - Policy violations not allowed in production" >> $GITHUB_STEP_SUMMARY
                echo "Fix all policy violations before production deployment" >> $GITHUB_STEP_SUMMARY
                exit 1
              elif [ "$ENV" = "staging" ]; then
                echo "‚ö†Ô∏è **WARNING**: Policy violations detected but allowing staging deployment" >> $GITHUB_STEP_SUMMARY
                echo "These issues must be fixed before production deployment" >> $GITHUB_STEP_SUMMARY
              else
                echo "‚ÑπÔ∏è Policy violations noted for development environment" >> $GITHUB_STEP_SUMMARY
              fi
            else
              echo "‚úÖ Policy validation passed - no violations found" >> $GITHUB_STEP_SUMMARY
            fi
          else
            echo "‚ûñ No terraform plan found, skipping policy validation" >> $GITHUB_STEP_SUMMARY
          fi

  website-tests:
    name: "üåê Website Content Tests"
    runs-on: ubuntu-latest
    timeout-minutes: 8
    needs: info
    if: needs.info.outputs.has_website_changes == 'true' || github.event.inputs.skip_build_check == 'true' || github.event.inputs.force_all_jobs == 'true'
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Download Build Artifacts
        uses: actions/download-artifact@v4
        continue-on-error: true
        with:
          name: build-artifacts-${{ needs.info.outputs.build_id }}
          path: ./artifacts

      - name: Website Tests
        run: |
          echo "## üåê Website Content Tests" >> $GITHUB_STEP_SUMMARY

          # Extract website artifacts if available
          if [ -f "artifacts/website-*.tar.gz" ]; then
            mkdir -p website-test
            tar -xzf artifacts/website-*.tar.gz -C website-test
          else
            cp -r src website-test
          fi

          # Test HTML structure
          ERRORS=0

          # Check for required HTML elements
          if grep -q "<title>" website-test/index.html; then
            echo "‚úÖ index.html has title tag" >> $GITHUB_STEP_SUMMARY
          else
            echo "‚ùå index.html missing title tag" >> $GITHUB_STEP_SUMMARY
            ERRORS=$((ERRORS + 1))
          fi

          if grep -q "<meta.*viewport" website-test/index.html; then
            echo "‚úÖ index.html has viewport meta tag" >> $GITHUB_STEP_SUMMARY
          else
            echo "‚ö†Ô∏è index.html missing viewport meta tag" >> $GITHUB_STEP_SUMMARY
          fi

          # Check 404 page
          if [ -f "website-test/404.html" ]; then
            echo "‚úÖ 404.html exists" >> $GITHUB_STEP_SUMMARY
          else
            echo "‚ùå 404.html missing" >> $GITHUB_STEP_SUMMARY
            ERRORS=$((ERRORS + 1))
          fi

          # Check robots.txt
          if [ -f "website-test/robots.txt" ]; then
            echo "‚úÖ robots.txt exists" >> $GITHUB_STEP_SUMMARY
          else
            echo "‚ùå robots.txt missing" >> $GITHUB_STEP_SUMMARY
            ERRORS=$((ERRORS + 1))
          fi

          if [ $ERRORS -gt 0 ]; then
            echo "‚ùå Website tests failed with $ERRORS errors" >> $GITHUB_STEP_SUMMARY
            exit 1
          fi

  pre-deployment-usability:
    name: "üåê Pre-Deployment Usability Tests"
    runs-on: ubuntu-latest
    timeout-minutes: 10
    needs: info
    if: needs.info.outputs.environment != 'dev' || github.event.inputs.force_all_jobs == 'true'
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Pre-Deployment Usability Testing
        run: |
          echo "## üåê Pre-Deployment Usability Tests" >> $GITHUB_STEP_SUMMARY
          echo "**Testing current live environment before deployment**" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          # Make usability test script executable
          chmod +x test/usability/run-usability-tests.sh

          # Run usability tests on current environment
          ENV="${{ needs.info.outputs.environment }}"
          echo "**Environment:** $ENV" >> $GITHUB_STEP_SUMMARY
          echo "**Purpose:** Validate current live environment before deploying new changes" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          if bash test/usability/run-usability-tests.sh "$ENV"; then
            echo "‚úÖ Pre-deployment usability tests passed" >> $GITHUB_STEP_SUMMARY
            echo "- Current $ENV environment is healthy" >> $GITHUB_STEP_SUMMARY
            echo "- Ready to proceed with deployment" >> $GITHUB_STEP_SUMMARY
          else
            echo "‚ö†Ô∏è Pre-deployment usability tests detected issues" >> $GITHUB_STEP_SUMMARY
            echo "- Current $ENV environment has problems" >> $GITHUB_STEP_SUMMARY
            echo "- These issues exist before new deployment" >> $GITHUB_STEP_SUMMARY

            # For staging, warn but continue; for production, this should block
            if [ "$ENV" = "prod" ]; then
              echo "‚ùå **PRODUCTION DEPLOYMENT BLOCKED** - Current environment has issues" >> $GITHUB_STEP_SUMMARY
              echo "Fix current production issues before deploying" >> $GITHUB_STEP_SUMMARY
              exit 1
            else
              echo "‚ö†Ô∏è Proceeding with deployment - will validate post-deployment" >> $GITHUB_STEP_SUMMARY
            fi
          fi

      - name: Upload Pre-Deployment Test Results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: pre-deployment-usability-results-${{ needs.info.outputs.test_id }}
          path: test/usability/test-results/
          retention-days: 7


  summary:
    name: "üìä Test Summary"
    runs-on: ubuntu-latest
    timeout-minutes: 5
    needs: [info, infrastructure-tests, policy-validation, website-tests, pre-deployment-usability]
    if: needs.info.result == 'success'
    outputs:
      tests_passed: ${{ steps.summary.outputs.tests_passed }}
    steps:
      - name: Download Unit Test Results
        uses: actions/download-artifact@v4
        continue-on-error: true
        with:
          name: unit-test-results-${{ needs.info.outputs.test_id }}
          path: ./test-results

      - name: Test Summary
        id: summary
        run: |
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## üìä Test Results Summary" >> $GITHUB_STEP_SUMMARY
          echo "| Test Suite | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|------------|--------|" >> $GITHUB_STEP_SUMMARY
          echo "| Infrastructure | ${{ needs.infrastructure-tests.result == 'success' && '‚úÖ Passed' || needs.infrastructure-tests.result == 'skipped' && '‚ûñ Skipped' || '‚ùå Failed' }}" >> $GITHUB_STEP_SUMMARY
          echo "| Policy Validation | ${{ needs.policy-validation.result == 'success' && '‚úÖ Passed' || needs.policy-validation.result == 'skipped' && '‚ûñ Skipped' || '‚ùå Failed' }}" >> $GITHUB_STEP_SUMMARY
          echo "| Website Content | ${{ needs.website-tests.result == 'success' && '‚úÖ Passed' || needs.website-tests.result == 'skipped' && '‚ûñ Skipped' || '‚ùå Failed' }}" >> $GITHUB_STEP_SUMMARY
          echo "| Pre-Deployment Usability | ${{ needs.pre-deployment-usability.result == 'success' && '‚úÖ Passed' || needs.pre-deployment-usability.result == 'skipped' && '‚ûñ Skipped' || '‚ùå Failed' }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          # Display detailed unit test results if available
          if [ -f "./test-results/test-summary.json" ]; then
            TOTAL_TESTS=$(jq -r '.individual_tests.total' ./test-results/test-summary.json 2>/dev/null || echo "N/A")
            PASSED_TESTS=$(jq -r '.individual_tests.passed' ./test-results/test-summary.json 2>/dev/null || echo "N/A")
            FAILED_TESTS=$(jq -r '.individual_tests.failed' ./test-results/test-summary.json 2>/dev/null || echo "N/A")
            SUCCESS_RATE=$(jq -r '.individual_tests.success_rate' ./test-results/test-summary.json 2>/dev/null || echo "N/A")
            
            echo "### üèóÔ∏è Infrastructure Unit Tests Details" >> $GITHUB_STEP_SUMMARY
            echo "- **Total Tests**: $TOTAL_TESTS" >> $GITHUB_STEP_SUMMARY
            echo "- **Passed**: $PASSED_TESTS" >> $GITHUB_STEP_SUMMARY
            echo "- **Failed**: $FAILED_TESTS" >> $GITHUB_STEP_SUMMARY
            echo "- **Success Rate**: $SUCCESS_RATE%" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY

            # Show failed test details if any failures occurred
            if [ "$FAILED_TESTS" != "0" ] && [ "$FAILED_TESTS" != "N/A" ]; then
              echo "### ‚ùå Failed Test Details" >> $GITHUB_STEP_SUMMARY
              
              # Look for failed test suite logs
              for log_file in ./test-results/*.log; do
                if [ -f "$log_file" ] && grep -q "ERROR" "$log_file"; then
                  suite_name=$(basename "$log_file" .log)
                  echo "#### **$suite_name**" >> $GITHUB_STEP_SUMMARY
                  
                  # Extract and show key failure information
                  grep "ERROR" "$log_file" | head -5 | while read -r line; do
                    clean_error="${line#*ERROR}"
                    echo "- $clean_error" >> $GITHUB_STEP_SUMMARY
                  done
                  echo "" >> $GITHUB_STEP_SUMMARY
                fi
              done
            fi
          elif [ "${{ needs.infrastructure-tests.result }}" = "failure" ]; then
            echo "### üèóÔ∏è Infrastructure Unit Tests Details" >> $GITHUB_STEP_SUMMARY
            echo "‚ùå **Unit tests failed** - Test results not available for detailed analysis" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
          fi

          # Check overall status
          FAILED_JOBS=""
          if [ "${{ needs.infrastructure-tests.result }}" = "failure" ]; then FAILED_JOBS="${FAILED_JOBS}Infrastructure "; fi
          if [ "${{ needs.policy-validation.result }}" = "failure" ]; then FAILED_JOBS="${FAILED_JOBS}Policy "; fi
          if [ "${{ needs.website-tests.result }}" = "failure" ]; then FAILED_JOBS="${FAILED_JOBS}Website "; fi
          if [ "${{ needs.pre-deployment-usability.result }}" = "failure" ]; then FAILED_JOBS="${FAILED_JOBS}Pre-Deployment-Usability "; fi

          if [ -z "$FAILED_JOBS" ]; then
            echo "üéâ **ALL TESTS PASSED** - Ready for RUN phase" >> $GITHUB_STEP_SUMMARY
            echo "tests_passed=true" >> $GITHUB_OUTPUT
          else
            echo "‚ùå **TESTS FAILED** - Failed jobs: $FAILED_JOBS" >> $GITHUB_STEP_SUMMARY
            echo "tests_passed=false" >> $GITHUB_OUTPUT
          fi
